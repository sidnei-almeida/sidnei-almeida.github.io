================================================================================
FACIAL EMOTION CLASSIFIER API - ENDPOINTS SUMMARY
================================================================================

BASE URL: https://salmeida-vgg16-emotion-classifier.hf.space

================================================================================
1. GET / - API Information
================================================================================
Description: Returns basic API information

Method: GET
URL: https://salmeida-vgg16-emotion-classifier.hf.space/

Response:
{
  "message": "Facial Emotion Classifier API",
  "version": "1.0.0",
  "docs": "/docs",
  "health": "/health"
}

================================================================================
2. GET /health - Health Check
================================================================================
Description: Checks API status and if models are loaded

Method: GET
URL: https://salmeida-vgg16-emotion-classifier.hf.space/health

Response:
{
  "status": "healthy",
  "model_loaded": true,
  "cascade_loaded": true
}

================================================================================
3. POST /predict - Single Image Prediction
================================================================================
Description: Predicts emotion from a single uploaded image
             Detects the first face found in the image

Method: POST
URL: https://salmeida-vgg16-emotion-classifier.hf.space/predict
Content-Type: multipart/form-data

Request:
  - Form field name: "file"
  - File types: PNG, JPG, JPEG
  - Max file size: Check API limits

Response (Success - 200):
{
  "emotion": "happy",
  "confidence": 0.95,
  "probabilities": {
    "angry": 0.01,
    "disgust": 0.01,
    "fear": 0.01,
    "happy": 0.95,
    "neutral": 0.01,
    "sad": 0.005,
    "surprise": 0.005
  },
  "message": "ðŸ˜„ Pure joy! Keep spreading that contagious smile!"
}

Error Responses:
  - 400: Invalid image or no face detected
  - 500: Error processing image
  - 503: Model not loaded

JavaScript Example:
const formData = new FormData();
formData.append('file', fileInput.files[0]);

fetch('https://salmeida-vgg16-emotion-classifier.hf.space/predict', {
  method: 'POST',
  body: formData
})
.then(response => response.json())
.then(data => {
  console.log('Emotion:', data.emotion);
  console.log('Confidence:', data.confidence);
  console.log('Message:', data.message);
})
.catch(error => console.error('Error:', error));

================================================================================
4. POST /predict/batch - Batch Prediction (Multiple Images)
================================================================================
Description: Processes multiple images and returns predictions for all faces
             detected in all images

Method: POST
URL: https://salmeida-vgg16-emotion-classifier.hf.space/predict/batch
Content-Type: multipart/form-data

Request:
  - Form field name: "files" (multiple files allowed)
  - File types: PNG, JPG, JPEG

Response (Success - 200):
{
  "results": [
    {
      "filename": "imagem1.jpg",
      "faces": [
        {
          "emotion": "happy",
          "confidence": 0.92,
          "probabilities": {
            "angry": 0.02,
            "disgust": 0.01,
            "fear": 0.01,
            "happy": 0.92,
            "neutral": 0.02,
            "sad": 0.01,
            "surprise": 0.01
          },
          "message": "ðŸ˜„ Pure joy! Keep spreading that contagious smile!",
          "face_coordinates": {
            "x": 100,
            "y": 150,
            "width": 200,
            "height": 200
          }
        }
      ]
    },
    {
      "filename": "imagem2.jpg",
      "faces": [...]
    },
    {
      "filename": "imagem3.jpg",
      "error": "No face detected"
    }
  ]
}

JavaScript Example:
const formData = new FormData();
fileInput.files.forEach(file => {
  formData.append('files', file);
});

fetch('https://salmeida-vgg16-emotion-classifier.hf.space/predict/batch', {
  method: 'POST',
  body: formData
})
.then(response => response.json())
.then(data => {
  data.results.forEach(result => {
    if (result.faces) {
      result.faces.forEach(face => {
        console.log(`${result.filename}: ${face.emotion} (${face.confidence})`);
      });
    } else {
      console.log(`${result.filename}: ${result.error}`);
    }
  });
});

================================================================================
5. GET /emotions - Available Emotions List
================================================================================
Description: Returns list of emotions the model can detect

Method: GET
URL: https://salmeida-vgg16-emotion-classifier.hf.space/emotions

Response:
{
  "emotions": [
    "angry",
    "disgust",
    "fear",
    "happy",
    "neutral",
    "sad",
    "surprise"
  ],
  "emotion_messages": {
    "angry": "ðŸ˜  Looks like someone woke up on the wrong side of bed today! Stay calm!",
    "disgust": "ðŸ¤¢ Eww! Something left you disgusted. Let's improve that mood?",
    "fear": "ðŸ˜¨ Fear? Don't be afraid! You're stronger than you think!",
    "happy": "ðŸ˜„ Pure joy! Keep spreading that contagious smile!",
    "neutral": "ðŸ˜ Neutral like Ironically. Let's add some color?",
    "sad": "ðŸ˜¢ Sadness in the air... Remember that after rain comes the rainbow!",
    "surprise": "ðŸ˜² Wow! What a surprise! The world is full of unexpected things!"
  }
}

================================================================================
6. GET /docs - Interactive API Documentation
================================================================================
Description: Swagger UI for interactive API testing

URL: https://salmeida-vgg16-emotion-classifier.hf.space/docs

================================================================================
7. GET /redoc - Alternative API Documentation
================================================================================
Description: ReDoc alternative documentation

URL: https://salmeida-vgg16-emotion-classifier.hf.space/redoc

================================================================================
EMOTIONS REFERENCE
================================================================================
The model can detect 7 emotions:

1. angry    - ðŸ˜  Anger/Frustration
2. disgust  - ðŸ¤¢ Disgust/Revulsion
3. fear     - ðŸ˜¨ Fear/Anxiety
4. happy    - ðŸ˜„ Happiness/Joy
5. neutral  - ðŸ˜ Neutral/No emotion
6. sad      - ðŸ˜¢ Sadness/Melancholy
7. surprise - ðŸ˜² Surprise/Astonishment

================================================================================
RESPONSE FIELDS EXPLANATION
================================================================================

emotion (string):
  - The detected emotion name
  - Values: "angry", "disgust", "fear", "happy", "neutral", "sad", "surprise"

confidence (float):
  - Confidence score of the prediction
  - Range: 0.0 to 1.0
  - Higher values = more confident prediction

probabilities (object):
  - Probability distribution for all emotions
  - Keys: emotion names
  - Values: probability scores (0.0 to 1.0)
  - All probabilities sum to ~1.0

message (string):
  - Friendly message related to the detected emotion
  - Includes emoji

face_coordinates (object, batch only):
  - Position of detected face in the image
  - x: X coordinate (pixels)
  - y: Y coordinate (pixels)
  - width: Face width (pixels)
  - height: Face height (pixels)

================================================================================
ERROR HANDLING
================================================================================

Status Codes:
  200 - Success
  400 - Bad Request (invalid image, no face detected)
  500 - Internal Server Error (processing error)
  503 - Service Unavailable (model not loaded)

Error Response Format:
{
  "detail": "Error message description"
}

Common Errors:
  - "No face detected in the image"
  - "File must be an image (PNG, JPG, JPEG)"
  - "Model not loaded. Please check server logs."
  - "Face cascade not loaded. Please check server logs."

================================================================================
CORS POLICY
================================================================================
CORS is enabled for all origins (*)
No authentication required

================================================================================
NOTES FOR FRONT-END TEAM
================================================================================

1. File Upload:
   - Use FormData for file uploads
   - Field name must be "file" (singular) for /predict
   - Field name must be "files" (plural) for /predict/batch

2. Image Requirements:
   - Supported formats: PNG, JPG, JPEG
   - Image must contain at least one detectable face
   - Face should be clearly visible and front-facing for best results

3. Response Handling:
   - Always check for errors in response
   - In batch mode, check for "error" field in each result
   - Confidence threshold: Consider filtering results below 0.5

4. Performance:
   - Single prediction: ~1-3 seconds
   - Batch prediction: Depends on number of images and faces
   - Health check before making predictions is recommended

5. Testing:
   - Use /docs endpoint for interactive testing
   - Test with various image sizes and qualities
   - Handle edge cases (no face, multiple faces, etc.)

================================================================================
QUICK START EXAMPLE (JavaScript/React)
================================================================================

// Single Image Prediction
async function predictEmotion(imageFile) {
  const formData = new FormData();
  formData.append('file', imageFile);
  
  try {
    const response = await fetch(
      'https://salmeida-vgg16-emotion-classifier.hf.space/predict',
      {
        method: 'POST',
        body: formData
      }
    );
    
    if (!response.ok) {
      const error = await response.json();
      throw new Error(error.detail || 'Prediction failed');
    }
    
    const data = await response.json();
    return {
      emotion: data.emotion,
      confidence: data.confidence,
      message: data.message,
      probabilities: data.probabilities
    };
  } catch (error) {
    console.error('Error:', error);
    throw error;
  }
}

// Usage
const fileInput = document.querySelector('input[type="file"]');
fileInput.addEventListener('change', async (e) => {
  const file = e.target.files[0];
  if (file) {
    const result = await predictEmotion(file);
    console.log(`Detected emotion: ${result.emotion} (${result.confidence})`);
  }
});

================================================================================
END OF DOCUMENTATION
================================================================================

